---
allowed-tools: Bash(emacs:*), Bash(timeout:*), Read, Write, TodoWrite
description: Comprehensive testing of Doom Emacs configuration
---

# ğŸ§ª TEST CONFIG: Configuration Validation & Testing

Run comprehensive tests on your Doom Emacs configuration to ensure stability, performance, and functionality.

## Test Suite Overview:

### 1. **Syntax Validation Tests**
```bash
# Test basic Elisp syntax in configuration files
echo "ğŸ” Testing Elisp syntax..."

# Check init.el
emacs -Q --batch --eval "(condition-case err (load-file \"init.el\") (error (message \"ERROR in init.el: %s\" err)))" 2>&1

# Check config.el 
emacs -Q --batch --eval "(condition-case err (load-file \"config.el\") (error (message \"ERROR in config.el: %s\" err)))" 2>&1

# Check packages.el
emacs -Q --batch --eval "(condition-case err (load-file \"packages.el\") (error (message \"ERROR in packages.el: %s\" err)))" 2>&1
```

### 2. **Configuration Loading Tests**
```bash
# Test clean configuration loading
echo "ğŸš€ Testing configuration loading..."

# Test minimal startup
timeout 60s emacs --batch --eval "(message \"âœ… Basic loading successful\")" 2>&1 || echo "âŒ Basic loading failed"

# Test with user configuration
timeout 60s emacs --batch -l init.el --eval "(message \"âœ… Full config loading successful\")" 2>&1 || echo "âŒ Full config loading failed"
```

### 3. **Package Integrity Tests**  
```bash
# Test package loading and integrity
echo "ğŸ“¦ Testing package integrity..."

# Check for broken packages
~/.emacs.d/bin/doom doctor | grep -i "broken\|missing\|error" || echo "âœ… No broken packages detected"

# Test critical package loading
emacs --batch --eval "
(require 'package)
(package-initialize)
(dolist (pkg '(evil org magit))
  (condition-case err 
    (require pkg)
    (message \"âœ… Package %s loads successfully\" pkg)
    (error (message \"âŒ Package %s failed: %s\" pkg err))))
" 2>&1
```

### 4. **Keybinding Tests**
```bash
# Test critical keybinding functionality
echo "âŒ¨ï¸  Testing keybinding configuration..."

emacs --batch --eval "
(defun test-keybinding (key command)
  (condition-case err
    (if (key-binding (kbd key))
        (message \"âœ… Keybinding %s -> %s works\" key (key-binding (kbd key)))
      (message \"âš ï¸  Keybinding %s not bound\" key))
    (error (message \"âŒ Keybinding %s error: %s\" key err))))

(test-keybinding \"SPC f f\" 'find-file)
(test-keybinding \"SPC b b\" 'switch-to-buffer)
(test-keybinding \"SPC p p\" 'projectile-switch-project)
" 2>&1
```

### 5. **Performance Tests**
```bash
# Startup time tests
echo "âš¡ Testing startup performance..."

# Measure startup time (3 iterations)
echo "Startup time measurements:"
for i in {1..3}; do
    /usr/bin/time -f "Run $i: %e seconds" emacs --eval "(kill-emacs)" 2>&1 | grep "seconds"
done

# Memory usage test  
echo "Memory usage test:"
emacs --batch --eval "
(message \"Memory usage: %.2f MB\" 
  (/ (car (car (memory-use-counts))) 1048576.0))
" 2>&1
```

### 6. **Module-Specific Tests**
```bash
# Test specific Doom modules
echo "ğŸ—ï¸  Testing Doom modules..."

# Test org-mode setup
emacs --batch --eval "
(condition-case err
  (progn 
    (require 'org)
    (message \"âœ… Org-mode loads successfully\")
    (if (fboundp 'org-agenda)
        (message \"âœ… Org-agenda available\")
      (message \"âš ï¸  Org-agenda not available\")))
  (error (message \"âŒ Org-mode error: %s\" err)))
" 2>&1

# Test completion framework
emacs --batch --eval "
(condition-case err
  (cond
    ((require 'vertico nil t) (message \"âœ… Vertico completion available\"))
    ((require 'ivy nil t) (message \"âœ… Ivy completion available\"))
    ((require 'helm nil t) (message \"âœ… Helm completion available\"))
    (t (message \"âš ï¸  No completion framework detected\")))
  (error (message \"âŒ Completion framework error: %s\" err)))
" 2>&1
```

### 7. **External Tool Integration Tests**
```bash
# Test external tool integrations
echo "ğŸ”§ Testing external integrations..."

# Test git integration
which git > /dev/null && echo "âœ… Git available" || echo "âŒ Git not found"

# Test ripgrep for searching  
which rg > /dev/null && echo "âœ… Ripgrep available" || echo "âš ï¸  Ripgrep not found (search may be slower)"

# Test language servers if configured
which clangd > /dev/null && echo "âœ… Clangd available" || echo "â„¹ï¸  Clangd not found"
which python-language-server > /dev/null && echo "âœ… Python LSP available" || echo "â„¹ï¸  Python LSP not found"
```

### 8. **Configuration Stress Tests**
```bash
# Stress test the configuration
echo "ğŸ”¥ Running stress tests..."

# Large file handling test
emacs --batch --eval "
(condition-case err
  (progn
    (find-file \"/dev/null\")
    (insert (make-string 100000 ?a))
    (message \"âœ… Large buffer handling works\"))
  (error (message \"âŒ Large buffer test failed: %s\" err)))
" 2>&1

# Multiple buffer test
emacs --batch --eval "
(condition-case err
  (progn
    (dotimes (i 50) (get-buffer-create (format \"test-buffer-%d\" i)))
    (message \"âœ… Multiple buffer creation works\"))
  (error (message \"âŒ Multiple buffer test failed: %s\" err)))
" 2>&1
```

## Generate Test Report:

Create comprehensive test report:

```markdown
# ğŸ§ª Configuration Test Report

**Date**: $(date)
**Configuration**: $DOOM_CONFIG_DIR
**Emacs Version**: $(emacs --version | head -1)

## Test Summary
- **Total Tests Run**: [X]
- **Passed**: [Y] âœ…
- **Failed**: [Z] âŒ  
- **Warnings**: [W] âš ï¸
- **Overall Status**: [PASS/FAIL]

## Detailed Results

### Syntax Validation
- **init.el**: [âœ… Pass | âŒ Fail]
- **config.el**: [âœ… Pass | âŒ Fail]  
- **packages.el**: [âœ… Pass | âŒ Fail]

### Loading Tests
- **Basic Loading**: [âœ… Pass | âŒ Fail]
- **Full Configuration**: [âœ… Pass | âŒ Fail]
- **Load Time**: [X.X seconds]

### Package Integrity
- **Critical Packages**: [X/Y working]
- **Broken Packages**: [List if any]
- **Missing Dependencies**: [List if any]

### Performance Metrics
- **Average Startup Time**: [X.X seconds]
- **Memory Usage**: [X.X MB]
- **Performance Grade**: [A/B/C/D/F]

### Keybinding Tests
- **Leader Key Functions**: [X/Y working]
- **Critical Bindings**: [X/Y working]
- **Conflicts Detected**: [List if any]

### Module Tests
- **Org-mode**: [âœ… Pass | âŒ Fail]
- **Completion**: [Framework name] [âœ… Pass | âŒ Fail]
- **Evil Mode**: [âœ… Pass | âŒ Fail]
- **Magit**: [âœ… Pass | âŒ Fail]

### External Integrations
- **Git**: [âœ… Available | âŒ Missing]
- **Ripgrep**: [âœ… Available | âš ï¸ Missing]
- **Language Servers**: [List available]

### Stress Tests
- **Large Files**: [âœ… Pass | âŒ Fail]
- **Multiple Buffers**: [âœ… Pass | âŒ Fail]
- **Memory Stability**: [âœ… Pass | âŒ Fail]

## Issues Found
[List any critical issues that need attention]

## Warnings
[List any warnings or potential issues]

## Recommendations
[Suggestions for optimization or fixes]

## Performance Comparison
- **Previous Test**: [Date] - [X.X seconds]
- **Current Test**: [Date] - [Y.Y seconds]
- **Change**: [Â±Z.Z seconds]

---
*Generated by test-config command*
```

## Save Test Report:

Save to: `docs/tests/config-test-$(date +%Y%m%d-%H%M%S).md`

## Failure Response:

### If Critical Tests Fail:
1. **Backup Current Config**: Ensure backup exists
2. **Provide Debug Info**: Show detailed error messages
3. **Suggest Fixes**: Common solutions for detected issues
4. **Safe Mode**: Instructions for minimal configuration
5. **Recovery Steps**: How to restore working state

### If Performance Degrades:
1. **Profile Startup**: Detailed startup profiling
2. **Package Audit**: Check for resource-heavy packages
3. **Configuration Review**: Suggest optimizations
4. **Baseline Comparison**: Compare with previous benchmarks

## Integration Points:

- **Pre-commit Hook**: Run tests before committing config changes
- **CI/CD Pipeline**: Automated testing of configuration changes  
- **Performance Monitoring**: Track performance over time
- **Issue Tracking**: Create issues for failing tests

## Status Updates:

Update TodoWrite with:
- [ ] Syntax validation passed
- [ ] Configuration loads successfully
- [ ] Package integrity verified
- [ ] Performance benchmarks acceptable
- [ ] All critical functions working

## Summary Output:

```
ğŸ§ª Configuration Test Results:
â€¢ Status: [PASS/FAIL]
â€¢ Tests: [X passed, Y failed, Z warnings]
â€¢ Startup: [X.X seconds]
â€¢ Memory: [Y.Y MB]
â€¢ Issues: [None/List critical issues]
â€¢ Next Action: [Continue/Fix issues/Optimize]
```